#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=TrainNFSR-Europe
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=24:00:00
#SBATCH --output=cluster_workflow/slurm_outputs/train_europe_%A.out
#SBATCH --error=cluster_workflow/slurm_outputs/train_europe_%A.err

# Neural Field Super-Resolution Training
# Full Europe region (~30-70°N, -30-50°E)

mkdir -p logs

echo "============================================================"
echo " Job started: $(date)"
echo " Node: $(hostname)"
echo " GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader)"
echo "============================================================"

# Load modules
module purge
module load 2023
module load CUDA/12.4.0
module load Anaconda3/2023.07-2

# Activate conda environment
source activate neural-field-superres

# Navigate to project directory
cd /home/$USER/Neural-Field-Superres
export PYTHONPATH=".";

# Pull latest code
echo "Pulling latest code..."
git pull

# Run training
echo ""
echo "============================================================"
echo " Starting training (Full Europe)"
echo "============================================================"
python -m src.train fit --config config/default_europe.yaml

echo ""
echo "============================================================"
echo " Job completed: $(date)"
echo "============================================================"
