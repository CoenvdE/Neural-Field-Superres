#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=TrainNFSR-Scandinavia
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=24:00:00
#SBATCH --output=cluster_workflow/slurm_outputs/train_scandinavia_%A.out
#SBATCH --error=cluster_workflow/slurm_outputs/train_scandinavia_%A.err

# Neural Field Super-Resolution Training
# Region: Scandinavia (55-70°N, 5-30°E)

mkdir -p logs

echo "============================================================"
echo " Job started: $(date)"
echo " Node: $(hostname)"
echo " GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader)"
echo "============================================================"

# Load modules
module purge
module load 2023
module load CUDA/12.4.0
module load Anaconda3/2023.07-2

# Activate conda environment
source activate neural-field-superres
export PYTHONPATH=".";

# Navigate to project directory
cd /home/$USER/Neural-Field-Superres

# Pull latest code
echo "Pulling latest code..."
git pull

# Run training
echo ""
echo "============================================================"
echo " Starting training (Scandinavia)"
echo "============================================================"
python -m src.train fit --config config/default.yaml

echo ""
echo "============================================================"
echo " Job completed: $(date)"
echo "============================================================"
